{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f479d386",
   "metadata": {},
   "source": [
    "# Objectif : optimiser le modèle SVM déjà existant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a50ada",
   "metadata": {},
   "source": [
    "Matériel : données sonores de 200ms, matérialisées par 71 paramàtres. 2 classes : les voitures et les camions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5a022e",
   "metadata": {},
   "source": [
    "### Pour cela, nous utilisons les techniques suivantes :\n",
    "-GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f990f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Example script\n",
    "\n",
    "Script to perform some corrections in the brief audio project\n",
    "\n",
    "Created on Fri Jan 27 09:08:40 2023\n",
    "\n",
    "@author: ValBaron10\n",
    "\"\"\"\n",
    "\n",
    "# Import\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.io.wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from features_functions import compute_features\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# SVM\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# import de la grid search\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70bec800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to the files \n",
    "data_path = \"Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d7b9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1983, 71)\n",
      "1983\n"
     ]
    }
   ],
   "source": [
    "# Names of the classes\n",
    "classes_paths = [\"Cars/\", \"Trucks/\"]\n",
    "classes_names = [\"car\", \"truck\"]\n",
    "cars_list = [4,5,7,9,10,15,20,21,23,26,30,38,39,44,46,48,51,52,53,57]\n",
    "trucks_list = [2,4,10,11,13,20,22,25,27,30,31,32,33,35,36,39,40,45,47,48]\n",
    "nbr_of_sigs = 20 # Nbr of sigs in each class\n",
    "seq_length = 0.2 # Nbr of second of signal for one sequence\n",
    "nbr_of_obs = int(nbr_of_sigs*10/seq_length) # Each signal is 10 s long\n",
    "\n",
    "# Go to search for the files\n",
    "learning_labels = []\n",
    "for i in range(2*nbr_of_sigs):\n",
    "    if i < nbr_of_sigs:\n",
    "        name = f\"{classes_names[0]}{cars_list[i]}.wav\"\n",
    "        class_path = classes_paths[0]\n",
    "    else:\n",
    "        name = f\"{classes_names[1]}{trucks_list[i - nbr_of_sigs]}.wav\"\n",
    "        class_path = classes_paths[1]\n",
    "\n",
    "    # Read the data and scale them between -1 and 1\n",
    "    fs, data = sio.wavfile.read(data_path + class_path + name)\n",
    "    data = data.astype(float)\n",
    "    data = data/32768\n",
    "\n",
    "    # Cut the data into sequences (we take off the last bits)\n",
    "    data_length = data.shape[0]\n",
    "    nbr_blocks = int((data_length/fs)/seq_length)\n",
    "    seqs = data[:int(nbr_blocks*seq_length*fs)].reshape((nbr_blocks, int(seq_length*fs)))\n",
    "\n",
    "    for k_seq, seq in enumerate(seqs):\n",
    "        # Compute the signal in three domains\n",
    "        sig_sq = seq**2\n",
    "        sig_t = seq / np.sqrt(sig_sq.sum())\n",
    "        sig_f = np.absolute(np.fft.fft(sig_t))\n",
    "        sig_c = np.absolute(np.fft.fft(sig_f))\n",
    "\n",
    "        # Compute the features and store them\n",
    "        features_list = []\n",
    "        N_feat, features_list = compute_features(sig_t, sig_f[:sig_t.shape[0]//2], sig_c[:sig_t.shape[0]//2], fs)\n",
    "        features_vector = np.array(features_list)[np.newaxis,:]\n",
    "\n",
    "        if k_seq == 0 and i == 0:\n",
    "            learning_features = features_vector\n",
    "            learning_labels.append(classes_names[0])\n",
    "        elif i < nbr_of_sigs:\n",
    "            learning_features = np.vstack((learning_features, features_vector))\n",
    "            learning_labels.append(classes_names[0])\n",
    "        else:\n",
    "            learning_features = np.vstack((learning_features, features_vector))\n",
    "            learning_labels.append(classes_names[1])\n",
    "\n",
    "print(learning_features.shape)\n",
    "print(len(learning_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(learning_features, learning_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the labels\n",
    "labelEncoder = preprocessing.LabelEncoder().fit(y_train)\n",
    "learningLabelsStd = labelEncoder.transform(y_train)\n",
    "testLabelsStd = labelEncoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347cb75",
   "metadata": {},
   "source": [
    "### Création de la grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc34da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[CV 1/5] END C=0.001, gamma=1e-05, kernel=linear;, score=0.720 total time=   1.4s\n",
      "[CV 2/5] END C=0.001, gamma=1e-05, kernel=linear;, score=0.685 total time=   1.0s\n",
      "[CV 3/5] END C=0.001, gamma=1e-05, kernel=linear;, score=0.625 total time=   0.9s\n",
      "[CV 4/5] END C=0.001, gamma=1e-05, kernel=linear;, score=0.662 total time=   0.9s\n",
      "[CV 5/5] END C=0.001, gamma=1e-05, kernel=linear;, score=0.685 total time=   0.8s\n",
      "[CV 1/5] END C=0.001, gamma=1e-05, kernel=sigmoid;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=1e-05, kernel=sigmoid;, score=0.502 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=1e-05, kernel=sigmoid;, score=0.502 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=1e-05, kernel=sigmoid;, score=0.502 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=1e-05, kernel=sigmoid;, score=0.498 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, gamma=1e-05, kernel=rbf;, score=0.500 total time=   0.1s\n",
      "[CV 2/5] END ..C=0.001, gamma=1e-05, kernel=rbf;, score=0.502 total time=   0.1s\n",
      "[CV 3/5] END ..C=0.001, gamma=1e-05, kernel=rbf;, score=0.502 total time=   0.1s\n",
      "[CV 4/5] END ..C=0.001, gamma=1e-05, kernel=rbf;, score=0.502 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, gamma=1e-05, kernel=rbf;, score=0.498 total time=   0.1s\n",
      "[CV 1/5] END .C=0.001, gamma=1e-05, kernel=poly;, score=0.720 total time=   1.0s\n",
      "[CV 2/5] END .C=0.001, gamma=1e-05, kernel=poly;, score=0.710 total time=   1.3s\n",
      "[CV 3/5] END .C=0.001, gamma=1e-05, kernel=poly;, score=0.716 total time=   1.4s\n",
      "[CV 4/5] END .C=0.001, gamma=1e-05, kernel=poly;, score=0.729 total time=   1.0s\n",
      "[CV 5/5] END .C=0.001, gamma=1e-05, kernel=poly;, score=0.738 total time=   1.1s\n",
      "[CV 1/5] END C=0.001, gamma=0.001, kernel=linear;, score=0.720 total time=   3.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.001, kernel=linear;, score=0.685 total time=   1.1s\n",
      "[CV 3/5] END C=0.001, gamma=0.001, kernel=linear;, score=0.625 total time=   1.1s\n",
      "[CV 4/5] END C=0.001, gamma=0.001, kernel=linear;, score=0.662 total time=   1.1s\n",
      "[CV 5/5] END C=0.001, gamma=0.001, kernel=linear;, score=0.685 total time=   1.3s\n",
      "[CV 1/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=0.502 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=0.502 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=0.502 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=0.498 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, gamma=0.001, kernel=rbf;, score=0.500 total time=   0.2s\n",
      "[CV 2/5] END ..C=0.001, gamma=0.001, kernel=rbf;, score=0.502 total time=   0.3s\n",
      "[CV 3/5] END ..C=0.001, gamma=0.001, kernel=rbf;, score=0.502 total time=   0.2s\n",
      "[CV 4/5] END ..C=0.001, gamma=0.001, kernel=rbf;, score=0.502 total time=   0.1s\n",
      "[CV 5/5] END ..C=0.001, gamma=0.001, kernel=rbf;, score=0.498 total time=   0.1s\n",
      "[CV 1/5] END .C=0.001, gamma=0.001, kernel=poly;, score=0.799 total time=21.1min\n",
      "[CV 2/5] END .C=0.001, gamma=0.001, kernel=poly;, score=0.767 total time=37.2min\n"
     ]
    }
   ],
   "source": [
    ", # définir les paramètres de la gridSearch \n",
    "param_grid = {\n",
    "    'C' : [.001],\n",
    "    'gamma': [.01],\n",
    "    'kernel' : ['poly']\n",
    "             }\n",
    "\n",
    "grid= GridSearchCV(SVC(), param_grid, refit= True, verbose = 4 )\n",
    "\n",
    "# fiter le modèle pour la grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25666504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the model\n",
    "model = svm.SVC(C=.001, kernel='poly',gamma=.01, class_weight=None, probability=False)\n",
    "scaler = preprocessing.StandardScaler(with_mean=True).fit(X_train)\n",
    "learningFeatures_scaled = scaler.transform(X_train)\n",
    "\n",
    "model.fit(learningFeatures_scaled, learningLabelsStd)\n",
    "\n",
    "# Test the model\n",
    "testFeatures_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Matrix confusion\n",
    "plot_confusion_matrix(model, testFeatures_scaled, testLabelsStd) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56657fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
